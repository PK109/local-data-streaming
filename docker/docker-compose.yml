name: streaming-platform

services:
  postgres:
    image: postgres:13
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ../pg_data/psql_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    command: [ "postgres", "-c", "wal_level=logical" ] # requirement of kafka-connect service
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 2s
      retries: 5

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    hostname: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ../pg_data/pgadmin:/var/lib/pgadmin
    ports:
      - "80:80"

  kafka1:
    image: confluentinc/cp-kafka
    container_name: kafka1
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_LISTENERS: 'INTERNAL://kafka1:29092,CONTROLLER://kafka1:29093,EXTERNAL://0.0.0.0:9092'
      KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka1:29092,EXTERNAL://localhost:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'INTERNAL'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093,2@kafka2:29093,3@kafka3:29093'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_LOG4J_ROOT_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_TOOLS_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_LOGGERS: |-
        org.apache.zookeeper=${KAFKA_LOGLEVEL},\
        org.apache.kafka=${KAFKA_LOGLEVEL},\
        kafka=${KAFKA_LOGLEVEL},kafka.cluster=${KAFKA_LOGLEVEL},\
        kafka.controller=${KAFKA_LOGLEVEL},\
        kafka.coordinator=${KAFKA_LOGLEVEL},\
        kafka.log=${KAFKA_LOGLEVEL},\
        kafka.server=${KAFKA_LOGLEVEL},\
        kafka.zookeeper=${KAFKA_LOGLEVEL},\
        state.change.logger=${KAFKA_LOGLEVEL}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      CLUSTER_ID: 'p8fFEbKGQ22B6M_Da_vCBw'
      KAFKA_LOG_DIRS: '/tmp/combined-logs'

  kafka2:
    image: confluentinc/cp-kafka
    container_name: kafka2
    hostname: kafka2
    ports:
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_LISTENERS: 'INTERNAL://kafka2:29092,CONTROLLER://kafka2:29093,EXTERNAL://0.0.0.0:9093'
      KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka2:29092,EXTERNAL://localhost:9093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'INTERNAL'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093,2@kafka2:29093,3@kafka3:29093'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_LOG4J_ROOT_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_TOOLS_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_LOGGERS: |-
        org.apache.zookeeper=${KAFKA_LOGLEVEL},\
        org.apache.kafka=${KAFKA_LOGLEVEL},\
        kafka=${KAFKA_LOGLEVEL},kafka.cluster=${KAFKA_LOGLEVEL},\
        kafka.controller=${KAFKA_LOGLEVEL},\
        kafka.coordinator=${KAFKA_LOGLEVEL},\
        kafka.log=${KAFKA_LOGLEVEL},\
        kafka.server=${KAFKA_LOGLEVEL},\
        kafka.zookeeper=${KAFKA_LOGLEVEL},\
        state.change.logger=${KAFKA_LOGLEVEL}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      CLUSTER_ID: 'p8fFEbKGQ22B6M_Da_vCBw'
      KAFKA_LOG_DIRS: '/tmp/combined-logs'

  kafka3:
    image: confluentinc/cp-kafka
    container_name: kafka3
    hostname: kafka3
    ports:
      - "9094:9094"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_LISTENERS: 'INTERNAL://kafka3:29092,CONTROLLER://kafka3:29093,EXTERNAL://0.0.0.0:9094'
      KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka3:29092,EXTERNAL://localhost:9094'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'INTERNAL'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093,2@kafka2:29093,3@kafka3:29093'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG4J_ROOT_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_TOOLS_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_LOGGERS: |-
        org.apache.zookeeper=${KAFKA_LOGLEVEL},\
        org.apache.kafka=${KAFKA_LOGLEVEL},\
        kafka=${KAFKA_LOGLEVEL},kafka.cluster=${KAFKA_LOGLEVEL},\
        kafka.controller=${KAFKA_LOGLEVEL},\
        kafka.coordinator=${KAFKA_LOGLEVEL},\
        kafka.log=${KAFKA_LOGLEVEL},\
        kafka.server=${KAFKA_LOGLEVEL},\
        kafka.zookeeper=${KAFKA_LOGLEVEL},\
        state.change.logger=${KAFKA_LOGLEVEL}KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      CLUSTER_ID: 'p8fFEbKGQ22B6M_Da_vCBw'
      KAFKA_LOG_DIRS: '/tmp/combined-logs'

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.7.1
    container_name: kafka-connect
    hostname: kafka-connect
    # depends_on:
    #   - kafka1
    #   - kafka2
    #   - kafka3
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29092,kafka3:29092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "1"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      KAFKA_LOG4J_ROOT_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_TOOLS_LOGLEVEL: ${KAFKA_LOGLEVEL}
      CONNECT_DEBEZIUM_AUTO_OFFSET_RESET: "latest"
      CONNECT_REST_ADVERTISED_HOST_NAME: "localhost"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/jars"
    volumes:
      - ../jars/debezium-connector-postgres:/etc/kafka-connect/jars
    ports:
      - "8083:8083"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 3m
  
  kafka-ui:
    image: kafbat/kafka-ui
    container_name: kafka-ui
    hostname: kafka-ui
    ports:
      - 8080:8080
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'kafka1:29092,kafka2:29092,kafka3:29092'
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8082
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: kafka-connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
      KAFKA_LOG4J_ROOT_LOGLEVEL: ${KAFKA_LOGLEVEL}
      KAFKA_LOG4J_TOOLS_LOGLEVEL: ${KAFKA_LOGLEVEL}
      DYNAMIC_CONFIG_ENABLED: 'true'
  
  flink-client:
    build: ../sql-client/.
    container_name: flink-client
    hostname: flink-client
    command: bin/sql-client.sh -i /opt/flink/init/FLINK_SQL_INIT.sql -f /opt/flink/init/FLINK_SQL_JOB.sql
    depends_on:
      kafka-connect:
        condition: service_healthy
      
    volumes:
      - ../sql-client:/opt/flink/init/
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager

  jobmanager:
    build: ../sql-client/.
    container_name: jobmanager
    hostname: jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    volumes:
      - ../flink_data:/tmp/
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        rest.flamegraph.enabled: true
        web.backpressure.refresh-interval: 10000
        restart-strategy.type: exponential-delay
        restart-strategy.exponential-delay.max-backoff: 20 s
        restart-strategy.exponential-delay.reset-backoff-threshold: 1 min

  taskmanager:
    build: ../sql-client/.
    container_name: taskmanager
    hostname: taskmanager
    depends_on:
      - jobmanager
    command: taskmanager
    volumes:
      - ../flink_data:/tmp/
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 3
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000

  worker:
    image: worker
    container_name: python_worker
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      KAFKA_CONNECT_CONNECTOR_NAME: ${KAFKA_CONNECT_CONNECTOR_NAME}
      KAFKA_CONNECT_IMAGE_NAME: 'kafka-connect'
      PYTHONUNBUFFERED: 1
    volumes:
      - ../rides_data:/rides_data
    depends_on:
      postgres:
        condition: service_healthy

volumes:
  flink_data:
  pg_data:
